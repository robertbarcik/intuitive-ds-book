<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Being Aware | Authentic Data Science</title>
  <meta name="description" content="This is a book that allows anyone to become a Embedded Data Scientist in an intuitive way." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Being Aware | Authentic Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a book that allows anyone to become a Embedded Data Scientist in an intuitive way." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Being Aware | Authentic Data Science" />
  
  <meta name="twitter:description" content="This is a book that allows anyone to become a Embedded Data Scientist in an intuitive way." />
  

<meta name="author" content="Robert Barcik" />


<meta name="date" content="2020-03-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="observer.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Becoming Citizen Data Scientist</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Foreword to Authentic Data Science</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#current-state-of-this-book"><i class="fa fa-check"></i><b>1.1</b> Current state of this book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="being-aware.html"><a href="being-aware.html"><i class="fa fa-check"></i><b>2</b> Being Aware</a><ul>
<li class="chapter" data-level="2.1" data-path="being-aware.html"><a href="being-aware.html#five-cornerstones"><i class="fa fa-check"></i><b>2.1</b> Five Cornerstones</a></li>
<li class="chapter" data-level="2.2" data-path="being-aware.html"><a href="being-aware.html#defining-data-science"><i class="fa fa-check"></i><b>2.2</b> Defining Data Science</a></li>
<li class="chapter" data-level="2.3" data-path="being-aware.html"><a href="being-aware.html#disciplines-of-data-science"><i class="fa fa-check"></i><b>2.3</b> Disciplines of Data Science</a></li>
<li class="chapter" data-level="2.4" data-path="being-aware.html"><a href="being-aware.html#defining-data-scientist"><i class="fa fa-check"></i><b>2.4</b> Defining Data Scientist</a></li>
<li class="chapter" data-level="2.5" data-path="being-aware.html"><a href="being-aware.html#the-struggle-of-data-science"><i class="fa fa-check"></i><b>2.5</b> The Struggle of Data Science</a></li>
<li class="chapter" data-level="2.6" data-path="being-aware.html"><a href="being-aware.html#who-is-embedded-data-scientist"><i class="fa fa-check"></i><b>2.6</b> Who is Embedded Data Scientist</a></li>
<li class="chapter" data-level="2.7" data-path="being-aware.html"><a href="being-aware.html#value-of-embedded-data-scientist"><i class="fa fa-check"></i><b>2.7</b> Value of Embedded Data Scientist</a></li>
<li class="chapter" data-level="2.8" data-path="being-aware.html"><a href="being-aware.html#anyone-can-become-embedded-data-scientist"><i class="fa fa-check"></i><b>2.8</b> Anyone Can Become Embedded Data Scientist</a></li>
<li class="chapter" data-level="2.9" data-path="being-aware.html"><a href="being-aware.html#the-6-levels-of-embedded-data-scientist"><i class="fa fa-check"></i><b>2.9</b> The 6 Levels of Embedded Data Scientist</a></li>
<li class="chapter" data-level="2.10" data-path="being-aware.html"><a href="being-aware.html#real-world-experience"><i class="fa fa-check"></i><b>2.10</b> Real World Experience</a></li>
<li class="chapter" data-level="2.11" data-path="being-aware.html"><a href="being-aware.html#learning-without-math"><i class="fa fa-check"></i><b>2.11</b> Learning Without Math</a></li>
<li class="chapter" data-level="2.12" data-path="being-aware.html"><a href="being-aware.html#population-and-observation"><i class="fa fa-check"></i><b>2.12</b> Population and Observation</a></li>
<li class="chapter" data-level="2.13" data-path="being-aware.html"><a href="being-aware.html#knowing-entire-population"><i class="fa fa-check"></i><b>2.13</b> Knowing Entire Population</a><ul>
<li class="chapter" data-level="2.13.1" data-path="being-aware.html"><a href="being-aware.html#mode-median-and-mean"><i class="fa fa-check"></i><b>2.13.1</b> Mode, Median and Mean</a></li>
</ul></li>
<li class="chapter" data-level="2.14" data-path="being-aware.html"><a href="being-aware.html#not-knowing-entire-population"><i class="fa fa-check"></i><b>2.14</b> Not Knowing Entire Population</a><ul>
<li class="chapter" data-level="2.14.1" data-path="being-aware.html"><a href="being-aware.html#confidence-interval"><i class="fa fa-check"></i><b>2.14.1</b> Confidence Interval</a></li>
</ul></li>
<li class="chapter" data-level="2.15" data-path="being-aware.html"><a href="being-aware.html#predicting-future-unforeseen-values"><i class="fa fa-check"></i><b>2.15</b> Predicting Future &amp; Unforeseen Values</a><ul>
<li class="chapter" data-level="2.15.1" data-path="being-aware.html"><a href="being-aware.html#predicting-future-values"><i class="fa fa-check"></i><b>2.15.1</b> Predicting Future Values</a></li>
<li class="chapter" data-level="2.15.2" data-path="being-aware.html"><a href="being-aware.html#correlation-vs-causality"><i class="fa fa-check"></i><b>2.15.2</b> Correlation vs Causality</a></li>
<li class="chapter" data-level="2.15.3" data-path="being-aware.html"><a href="being-aware.html#predicting-unforeseen-values"><i class="fa fa-check"></i><b>2.15.3</b> Predicting Unforeseen Values</a></li>
<li class="chapter" data-level="2.15.4" data-path="being-aware.html"><a href="being-aware.html#association-rules"><i class="fa fa-check"></i><b>2.15.4</b> Association Rules</a></li>
</ul></li>
<li class="chapter" data-level="2.16" data-path="being-aware.html"><a href="being-aware.html#level-1-being-aware---reached"><i class="fa fa-check"></i><b>2.16</b> Level 1: Being Aware - Reached</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="observer.html"><a href="observer.html"><i class="fa fa-check"></i><b>3</b> Observer</a><ul>
<li class="chapter" data-level="3.1" data-path="observer.html"><a href="observer.html#about-this-level"><i class="fa fa-check"></i><b>3.1</b> About this level</a></li>
<li class="chapter" data-level="3.2" data-path="observer.html"><a href="observer.html#be-skeptical-about-data"><i class="fa fa-check"></i><b>3.2</b> Be Skeptical About Data</a></li>
<li class="chapter" data-level="3.3" data-path="observer.html"><a href="observer.html#data-science-project"><i class="fa fa-check"></i><b>3.3</b> Data Science Project</a></li>
<li class="chapter" data-level="3.4" data-path="observer.html"><a href="observer.html#your-contribution"><i class="fa fa-check"></i><b>3.4</b> Your Contribution</a></li>
<li class="chapter" data-level="3.5" data-path="observer.html"><a href="observer.html#data-and-computing"><i class="fa fa-check"></i><b>3.5</b> Data and Computing</a></li>
<li class="chapter" data-level="3.6" data-path="observer.html"><a href="observer.html#using-data"><i class="fa fa-check"></i><b>3.6</b> Using Data</a><ul>
<li class="chapter" data-level="3.6.1" data-path="observer.html"><a href="observer.html#r"><i class="fa fa-check"></i><b>3.6.1</b> R</a></li>
<li class="chapter" data-level="3.6.2" data-path="observer.html"><a href="observer.html#python"><i class="fa fa-check"></i><b>3.6.2</b> Python</a></li>
<li class="chapter" data-level="3.6.3" data-path="observer.html"><a href="observer.html#knime"><i class="fa fa-check"></i><b>3.6.3</b> Knime</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="observer.html"><a href="observer.html#descriptive-statistics"><i class="fa fa-check"></i><b>3.7</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="3.7.1" data-path="observer.html"><a href="observer.html#range"><i class="fa fa-check"></i><b>3.7.1</b> Range</a></li>
<li class="chapter" data-level="3.7.2" data-path="observer.html"><a href="observer.html#distributions"><i class="fa fa-check"></i><b>3.7.2</b> Distributions</a></li>
<li class="chapter" data-level="3.7.3" data-path="observer.html"><a href="observer.html#quantiles-percentiles"><i class="fa fa-check"></i><b>3.7.3</b> Quantiles &amp; Percentiles</a></li>
<li class="chapter" data-level="3.7.4" data-path="observer.html"><a href="observer.html#extreme-values-and-outliers"><i class="fa fa-check"></i><b>3.7.4</b> Extreme Values and Outliers</a></li>
<li class="chapter" data-level="3.7.5" data-path="observer.html"><a href="observer.html#percentages"><i class="fa fa-check"></i><b>3.7.5</b> Percentages</a></li>
<li class="chapter" data-level="3.7.6" data-path="observer.html"><a href="observer.html#comparing-distributions"><i class="fa fa-check"></i><b>3.7.6</b> Comparing Distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="observer.html"><a href="observer.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>3.8</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="3.9" data-path="observer.html"><a href="observer.html#baseline-model"><i class="fa fa-check"></i><b>3.9</b> Baseline Model</a></li>
<li class="chapter" data-level="3.10" data-path="observer.html"><a href="observer.html#limitations-of-data-based-models"><i class="fa fa-check"></i><b>3.10</b> Limitations of data-based models</a></li>
<li class="chapter" data-level="3.11" data-path="observer.html"><a href="observer.html#independent-features-and-target-feature"><i class="fa fa-check"></i><b>3.11</b> Independent Features and Target Feature</a></li>
<li class="chapter" data-level="3.12" data-path="observer.html"><a href="observer.html#labelled-and-unlabelled-data"><i class="fa fa-check"></i><b>3.12</b> Labelled and Unlabelled Data</a></li>
<li class="chapter" data-level="3.13" data-path="observer.html"><a href="observer.html#supervised-learning"><i class="fa fa-check"></i><b>3.13</b> Supervised Learning</a></li>
<li class="chapter" data-level="3.14" data-path="observer.html"><a href="observer.html#underfitting-and-overfitting"><i class="fa fa-check"></i><b>3.14</b> Underfitting and Overfitting</a></li>
<li class="chapter" data-level="3.15" data-path="observer.html"><a href="observer.html#validation-data"><i class="fa fa-check"></i><b>3.15</b> Validation data</a></li>
<li class="chapter" data-level="3.16" data-path="observer.html"><a href="observer.html#regression"><i class="fa fa-check"></i><b>3.16</b> Regression</a></li>
<li class="chapter" data-level="3.17" data-path="observer.html"><a href="observer.html#classification"><i class="fa fa-check"></i><b>3.17</b> Classification</a></li>
<li class="chapter" data-level="3.18" data-path="observer.html"><a href="observer.html#the-two-cultures"><i class="fa fa-check"></i><b>3.18</b> The Two Cultures</a></li>
<li class="chapter" data-level="3.19" data-path="observer.html"><a href="observer.html#basics-of-machine-learning"><i class="fa fa-check"></i><b>3.19</b> Basics of Machine Learning</a></li>
<li class="chapter" data-level="3.20" data-path="observer.html"><a href="observer.html#level-2-reached"><i class="fa fa-check"></i><b>3.20</b> Level 2 Reached</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="contributor-I.html"><a href="contributor-I.html"><i class="fa fa-check"></i><b>4</b> Contributor: Soft Skills</a><ul>
<li class="chapter" data-level="4.1" data-path="contributor-I.html"><a href="contributor-I.html#soft-skills"><i class="fa fa-check"></i><b>4.1</b> Soft skills</a></li>
<li class="chapter" data-level="4.2" data-path="contributor-I.html"><a href="contributor-I.html#project-tasks"><i class="fa fa-check"></i><b>4.2</b> Project &amp; tasks</a></li>
<li class="chapter" data-level="4.3" data-path="contributor-I.html"><a href="contributor-I.html#fitting-into-a-team"><i class="fa fa-check"></i><b>4.3</b> Fitting into a team</a><ul>
<li class="chapter" data-level="4.3.1" data-path="contributor-I.html"><a href="contributor-I.html#kaizen"><i class="fa fa-check"></i><b>4.3.1</b> Kaizen</a></li>
<li class="chapter" data-level="4.3.2" data-path="contributor-I.html"><a href="contributor-I.html#nemawashi"><i class="fa fa-check"></i><b>4.3.2</b> Nemawashi</a></li>
<li class="chapter" data-level="4.3.3" data-path="contributor-I.html"><a href="contributor-I.html#pdca-cycle"><i class="fa fa-check"></i><b>4.3.3</b> PDCA Cycle</a></li>
<li class="chapter" data-level="4.3.4" data-path="contributor-I.html"><a href="contributor-I.html#agile-scrum"><i class="fa fa-check"></i><b>4.3.4</b> Agile &amp; Scrum</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="contributor-I.html"><a href="contributor-I.html#legal-regulations"><i class="fa fa-check"></i><b>4.4</b> Legal regulations</a></li>
<li class="chapter" data-level="4.5" data-path="contributor-I.html"><a href="contributor-I.html#producing-valuable-output"><i class="fa fa-check"></i><b>4.5</b> Producing valuable output</a></li>
<li class="chapter" data-level="4.6" data-path="contributor-I.html"><a href="contributor-I.html#documenting-your-work"><i class="fa fa-check"></i><b>4.6</b> Documenting your work</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="contributor-II.html"><a href="contributor-II.html"><i class="fa fa-check"></i><b>5</b> Contributor: Part II</a><ul>
<li class="chapter" data-level="5.1" data-path="contributor-II.html"><a href="contributor-II.html#cloud"><i class="fa fa-check"></i><b>5.1</b> Cloud</a></li>
<li class="chapter" data-level="5.2" data-path="contributor-II.html"><a href="contributor-II.html#databases-and-data-lakes"><i class="fa fa-check"></i><b>5.2</b> Databases and Data Lakes</a></li>
<li class="chapter" data-level="5.3" data-path="contributor-II.html"><a href="contributor-II.html#sql"><i class="fa fa-check"></i><b>5.3</b> SQL</a></li>
<li class="chapter" data-level="5.4" data-path="contributor-II.html"><a href="contributor-II.html#programming"><i class="fa fa-check"></i><b>5.4</b> Programming</a></li>
<li class="chapter" data-level="5.5" data-path="contributor-II.html"><a href="contributor-II.html#data-preprocessing"><i class="fa fa-check"></i><b>5.5</b> Data Preprocessing</a></li>
<li class="chapter" data-level="5.6" data-path="contributor-II.html"><a href="contributor-II.html#data-visualisation"><i class="fa fa-check"></i><b>5.6</b> Data Visualisation</a></li>
<li class="chapter" data-level="5.7" data-path="contributor-II.html"><a href="contributor-II.html#statistics"><i class="fa fa-check"></i><b>5.7</b> Statistics</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="contributor-III.html"><a href="contributor-III.html"><i class="fa fa-check"></i><b>6</b> Contributor: Part I</a><ul>
<li class="chapter" data-level="6.1" data-path="contributor-III.html"><a href="contributor-III.html#collaboration-git"><i class="fa fa-check"></i><b>6.1</b> Collaboration &amp; Git</a></li>
<li class="chapter" data-level="6.2" data-path="contributor-III.html"><a href="contributor-III.html#learning"><i class="fa fa-check"></i><b>6.2</b> Learning</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="statistician.html"><a href="statistician.html"><i class="fa fa-check"></i><b>7</b> Statistician</a><ul>
<li class="chapter" data-level="7.1" data-path="statistician.html"><a href="statistician.html#pipeline"><i class="fa fa-check"></i><b>7.1</b> Pipeline</a></li>
<li class="chapter" data-level="7.2" data-path="statistician.html"><a href="statistician.html#productive-frameworks"><i class="fa fa-check"></i><b>7.2</b> Productive Frameworks</a></li>
<li class="chapter" data-level="7.3" data-path="statistician.html"><a href="statistician.html#decision-tree"><i class="fa fa-check"></i><b>7.3</b> Decision Tree</a></li>
<li class="chapter" data-level="7.4" data-path="statistician.html"><a href="statistician.html#bagging-boosting-stacking"><i class="fa fa-check"></i><b>7.4</b> Bagging, Boosting &amp; Stacking</a></li>
<li class="chapter" data-level="7.5" data-path="statistician.html"><a href="statistician.html#unsupervised-learning---clustering"><i class="fa fa-check"></i><b>7.5</b> Unsupervised learning - Clustering</a></li>
<li class="chapter" data-level="7.6" data-path="statistician.html"><a href="statistician.html#unsupervised-learning---data-reduction"><i class="fa fa-check"></i><b>7.6</b> Unsupervised learning - Data Reduction</a></li>
<li class="chapter" data-level="7.7" data-path="statistician.html"><a href="statistician.html#feature-selection"><i class="fa fa-check"></i><b>7.7</b> Feature Selection</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="project-responsible.html"><a href="project-responsible.html"><i class="fa fa-check"></i><b>8</b> Project Responsible</a><ul>
<li class="chapter" data-level="8.1" data-path="project-responsible.html"><a href="project-responsible.html#data-science-project-as-product"><i class="fa fa-check"></i><b>8.1</b> Data Science project as product</a></li>
<li class="chapter" data-level="8.2" data-path="project-responsible.html"><a href="project-responsible.html#assembling-a-team"><i class="fa fa-check"></i><b>8.2</b> Assembling a team</a></li>
<li class="chapter" data-level="8.3" data-path="project-responsible.html"><a href="project-responsible.html#statistics-1"><i class="fa fa-check"></i><b>8.3</b> Statistics</a></li>
<li class="chapter" data-level="8.4" data-path="project-responsible.html"><a href="project-responsible.html#data-engineering"><i class="fa fa-check"></i><b>8.4</b> Data Engineering</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="butter-knife.html"><a href="butter-knife.html"><i class="fa fa-check"></i><b>9</b> Butter Knife</a><ul>
<li class="chapter" data-level="9.1" data-path="butter-knife.html"><a href="butter-knife.html#soft-skills-1"><i class="fa fa-check"></i><b>9.1</b> Soft Skills</a></li>
<li class="chapter" data-level="9.2" data-path="butter-knife.html"><a href="butter-knife.html#algorithmic-feature-generation"><i class="fa fa-check"></i><b>9.2</b> Algorithmic feature generation</a></li>
<li class="chapter" data-level="9.3" data-path="butter-knife.html"><a href="butter-knife.html#programming-skills"><i class="fa fa-check"></i><b>9.3</b> Programming skills</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="uncategorized-topics.html"><a href="uncategorized-topics.html"><i class="fa fa-check"></i><b>10</b> Uncategorized topics</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Authentic Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="being-aware" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Being Aware</h1>
<div id="five-cornerstones" class="section level2">
<h2><span class="header-section-number">2.1</span> Five Cornerstones</h2>
<p>You will quickly notice that this book is structured quite differently compared to other offerings on the market. Let me reason about that, even before I introduce you to the structure and the transformation that this book offers. I have been a lecturer/trainer for a few years and I always notice that content does not matter as much as the <em>path through the content</em> as well as the <em>assumptions upon which the content is built</em>. Only if both of these are fine, the book/course/training can offer you (the reader/student) a <strong>transformation</strong> - taking you from where you are, to where you want to be. In this case I am hoping you would like to make a living within Data Science or create some amazing project within it!</p>
<p>This book is hence built on five cornerstones:</p>
<ul>
<li>Data Science is a practice of using data to create a direct benefit.<br />
</li>
<li>Embedded Data Scientist is becoming a crucial occupation.<br />
</li>
<li>Anyone can become a Embedded Data Scientist.<br />
</li>
<li>There are 6 levels of Embedded Data Scientist and these should act as a learning curve.<br />
</li>
<li>Math is not required as a teaching tool in order to train a Embedded Data Scientist and can be replaced by visualisation and intuition.</li>
</ul>
<p>Did I go crazy claiming that anyone can become a Data Scientist? And what about the Math which is appraised by everyone as the crucial tool within data science?!? Maybe I have, but these cornerstones (assumptions) worked for me as well as for my students within the past years. Let me in this chapter explain <strong>why</strong> I believe that these things might work out for you.</p>
</div>
<div id="defining-data-science" class="section level2">
<h2><span class="header-section-number">2.2</span> Defining Data Science</h2>
<p>The very first thing that I would like to do is to answer a simple question: <em>What is data and what is information?</em> The difference between the two is in their value. <strong>Data</strong> inherently do not have any value for their owner, simply because he/she cannot do anything beneficial upon them. On the other hand, <strong>information</strong> can be valuable for its owner. These two are however thinly connected - as <em>information</em> is derived from <em>data</em>, while this process is called <strong>Data Science</strong>. I will give you an example from my recent past on how I got a value out of Data Science.</p>
<p>I was always interested in my sleep, as I know that in order to live a happy life, I shall sleep well. The only two things I know really is how long I sleep and how do I feel in the morning. I then found an app on my phone which was promising to analyze my sleep and give me recommendations on how to improve my sleep. The app is using an accelerometer in my phone, recording my movements at night. During the first two nights, the app only collected <em>data</em> - every morning I was able to see various graphs on how I slept. After a week though, recommendations came such as “when you go to bed late, around 23:00, even if you sleep full 8 hours, your sleep quality suffers.”. This is already <em>information</em> which had a value for me. The app is Data Science <em>process</em> of creating valuable information from data.</p>
<p>If you now turn to search engines and start to search for Data Science terms, you will be overwhelmed by articles and (unfortunately) buzzwords - Machine Learning, Data Mining, Artificial Intelligence, Tensorflow, R, Python. These are either tools of Data Science or neighbouring fields. Do not get confused or overwhelmed by these. The book which you are reading is a way to master these methods, but first I want you to truly and deeply understand the crucial ideas of Data Science. This might actually be the most important message from this book - always keep in mind that the methods should always serve the purpose which Data Science has.</p>
<blockquote>
<p>Data Science is merely an art of turning data into information, which creates benefit.</p>
</blockquote>
<p>Sounds like a vague definition right? Indeed it is, and it acts as double edged sword. On one hand, there are vast applications for Data Scientists along with possible specializations. On the other hand, as the field is not strictly defined it causes problems not only to newcomers but even to experienced professionals, with knowing what <em>skillset</em> they even should have and what <em>methods</em> should they consider and learn. Take a look at following graph:</p>
<div class="figure"><span id="fig:data-mining-Venn-diagram"></span>
<img src="resources/01-being-aware/data-mining-Venn-diagram.png" alt="Overview of various fields in Data Science (Data Mining) as depicted by SAS Institute." width="510" />
<p class="caption">
Figure 2.1: Overview of various fields in Data Science (Data Mining) as depicted by SAS Institute.
</p>
</div>
<p>The picture depicts overview and overlaps of various <em>disciplines</em> within Data Science, previously more recognized as Data Mining. I think that as part of the definition of Data Science, it is necessary to take closer look at these disciplines, as some are ancient predecessors which gave birth to our wonderful field nowadays, while some are rather novel and were connected to it only recently.</p>
</div>
<div id="disciplines-of-data-science" class="section level2">
<h2><span class="header-section-number">2.3</span> Disciplines of Data Science</h2>
<p><strong>Statistics</strong> can be certainly named as the most crucial and oldest predessor of Data Science. Moreover, when students start to learn Data Science, they are often recommended to start with Statistics. There is a good reason for it - Statistics comprises a very heart of the field as you will learn soon, through terms such as Descriptive Statistics and Inferential Statistics. Practitioners of Statistics have been for more than two centuries interested in deriving valuable information out of data. Earliest examples include a lot of demographics data, such as population census. Yet, I would like you as reader kindly ask you to not fixate your mind on Statistics, as many other disciplines are of crucial importance.</p>
<p><strong>Databases</strong>, as you will learn are a purposed collections of data. Companies have been for decades deciding to create databases of their products, customers, equipment and many more. Databses have to be not only created, but also maintained and curated. Without access to the data at the end of the day, we are hardly going to create any valuable information. We are going to dig a little into this field in later chapters of this book and you will get even <em>data engineering</em> knowledge.</p>
<p><strong>Knowledge Discovery in Data (KDD) and Data Mining</strong> started to occur as disciplines simply because databases existed, and companies wanted to derive the value out of them. Imagine you have a database about sales of your products. Why now use some tools from Statistics to gain more knowledge about your business? And so the origins of Data Mining arose - the art of mining jewels out of the mountains made up of data. In fact, if someone asked me what is the difference between Data Mining and Data Science, I would say that these two are pretty <em>close to each other</em>. The tipping point of when Data Science became predominant was when Machine Learning came into scene, as you can see from Google Trends.</p>
<div class="figure"><span id="fig:data-mining-data-science"></span>
<img src="resources/01-being-aware/data-mining-data-science.jpg" alt="Popularity comparison of three terms - Data Mining, Data Science and Machine Learning. Picture from Google Trends."  />
<p class="caption">
Figure 2.2: Popularity comparison of three terms - Data Mining, Data Science and Machine Learning. Picture from Google Trends.
</p>
</div>
<p><strong>Machine Learning</strong> is a discipline within which we are letting machines learn based on the data. We are going to deal with this topic a lot in later chapters, as it comprises a large part of Data Science nowadays for a simple reason. As it turns out, if we let a machine learn based on some historical data (i.e. product sales) it might be able to discover powerful patterns (i.e. if a customer buys product A, recommend him product B as he is likely to purchase it). The reason why we let machines learn, instead of trying to find patterns ourselves (such as through Statistics) is simply because often times they can be more powerful than us, humans. If we let machine and 3 year-old baby compete at recognising cats at pictures, the child be fine with competing. If we however let even doctor compete at identifying signs of diabetic retinopathy in eye images, it will already be probably unfair fight. Moreover, machine will be able to do identifications significantly faster.</p>
<p>Machine Learning is then what connects Data Science to <strong>Artificial Intelligence</strong>. This last field might be probably the most complex as it not only works with data and information; but also with automation, robotics and creation of intelligent systems. I think it is the easiest to imagine how these three fields; Data Science, Machine Learning and Artificial Intelligence work together is by looking at humanoid robot Pepper. This cute and handy robot can move around your house and help you with various things. In order to do so, it collects and processes various data from surrounding environment (Data Science), makes sense out of these with learned models (Machine Learning) and puts it together to an intelligent humanoid machine (Artificial Intelligence).</p>
<div class="figure"><span id="fig:pepper-robot"></span>
<img src="resources/01-being-aware/pepper-robot.jpg" alt="Humanoid robot Pepper as a great example where fields of Data Science, Machine Learning and Artificial Intelligence overlap. Picture by Alex Knight on Pexels."  />
<p class="caption">
Figure 2.3: Humanoid robot Pepper as a great example where fields of Data Science, Machine Learning and Artificial Intelligence overlap. Picture by Alex Knight on Pexels.
</p>
</div>
</div>
<div id="defining-data-scientist" class="section level2">
<h2><span class="header-section-number">2.4</span> Defining Data Scientist</h2>
<p>Now that we know what Data Science is, it is quite easy to define who a Data Scientist is. He/She is a practitioner of this field, who uses its disciplines(methods to achieve its goal. Usually, a Data Scientist has general education in three areas - Programming, Mathematics and Statistics. Notice that none of these areas deal with <em>context</em> or <em>domain</em> such as Banking, Medicine or Engineering. Thus Data Scientist - by definition, should be <em>domain-agnostic</em>. We can see this also in the definition within Oxford Dictionary:</p>
<blockquote>
<p>a person employed to analyse and interpret complex digital data, such as the usage statistics of a website, especially in order to assist a business in its decision-making</p>
</blockquote>
<p>He/she should be able to join any of the mentioned domains, and many more, apply the methods of Data Science to fulfill the goal of creating value, through information, out of data. This is a very important point for you as you will now see.</p>
</div>
<div id="the-struggle-of-data-science" class="section level2">
<h2><span class="header-section-number">2.5</span> The Struggle of Data Science</h2>
<p>Now that you heard about Data Scientists, who are Embedded Data Scientists? I think they are the most crucial occupations in the future of the field of Data Science. You heard me right, not the original Data Scientists, but the new generation of Embedded Data Scientists. Let me show you why.</p>
<p>Data Science as a field has been around for decades in one form or another. There have been market analysts, risk modellers, product developers, artificial intelligence developers and so on. If we however relate to the definition of Data Science above in a way that a Data Scientist can essentially come to any company and make use of its data to create benefit, we can go back to the millenia breakthrough. Universities start to offer programs with names like “Data Analysis”, “Business Intelligence’’ and first candidates are leaving these programs. It feels like the field is growing tremendously - growth in GPU powers, Deep Learning, Automated Machine Learning products. Especially since the 2010s, job advertisements revolving around Data Science are exploding! Though is the field really growing from the perspective of the market? I would say very slowly, simply because the <em>created benefit for companies (and their customers)</em> is growing slowly.</p>
<p>This is caused by the fact that the field is still relying on the slow and linear growth of the first generation of Data Scientists - ones having formal education, being able to guarantee the work. Now two scenarios can occur when a company attempts to create benefit/profit through data science:</p>
<ol style="list-style-type: decimal">
<li>It hires <em>actual</em> Data Scientists, whereas costs to hire them are tremendous and what is even more expensive is to make them productive. Finding for them process which can be optimized through their methods and then properly optimizing it is lengthy and costly. As these are domain-agnostic, the company needs to also educate them and integrate them into contexts. Company slowly loses interest and stops believing that actual profit in a decent scale can be created this way.</li>
<li>It does not hire <em>actual</em> Data Scientists, as they are expensive and scarce. People who come to the company have been originally trained in other areas and are now expected to be <em>actual</em> Data Scientists. The company has just thrown away a lot of their potential as only their recently acquired experience are counted and not their original context. The hirees are now pushed equally hard as the <em>actual</em> Data Scientists and are struggling to create valuable products. Company slowly looses interest and stops believing that actual profit in decent scale can be created this way.</li>
</ol>
<p>You might now disagree with me and say I am too much of a negativist. To justify my thinking in your mind, let me ask you only one question. As employees, we are expected to create larger profits than what we cost our employer. How many data scientists you know, who can prove that they are repeatedly creating profit for their companies? Not so many, right? Thereafter I believe that the above described struggle holds.</p>
</div>
<div id="who-is-embedded-data-scientist" class="section level2">
<h2><span class="header-section-number">2.6</span> Who is Embedded Data Scientist</h2>
<p>I believe that the answer to this struggle of many companies is recognition of a Embedded Data Scientist (the ones coming in point 2 above) and definition of their relationship to Data Scientists. The market is begging us to do so and we can see it by who comes to job interviews when we make an advertisement for a position of a Data Scientist. These are people who do not have formal education or direct experience. Let me tell you one story from my past.</p>
<p>I worked in a large organization with thousands of employees as a Data Scientist. Out of nowhere, I received an email from a colleague I never heard of before. She claimed that she is really passionate about the methods of predictive modelling and Data Science and is eager to apply these methods in her CRM department. We met and she showed me R-script in which she tried a bunch of Machine Learning algorithms and preprocessing methods. What I did in turn was that I encouraged her to continue with the passion because the field has a future and I advised her about further methods she can try.</p>
<p>Only years later, I realized my mistakes in that meeting and that I met one of the first Embedded Data Scientists. I then learned that she left the company as she never managed to get her passion for productive work. I was one of the reasons why she churned because I gave her advice on how to become the first generation Data Scientist, not the second generation of Embedded Data Scientist. Let’s look at the definition by Gartner in 2016 of Citizen Data Scientist:</p>
<blockquote>
<p>Citizen data science bridges the gap between mainstream self-service data discovery by business users and the advanced analytics techniques of data scientists.</p>
</blockquote>
<p>This colleague of mine was originally in the first part of definition (business user), while I was in the second part of it (advanced analytics). She was trying to become a bridge between the two, without even realising it! Unfortunately I am only smarter years later and when the same situation happens these days, I react in a different way. Also, the company which I work for now is smarter and allows for an environment where Embedded Data Scientists are given space.</p>
<p>She had something that I could never have - expertise in her CRM department and if I was about to give her advice now it would be:</p>
<ul>
<li>Focus on how a predictive model will create benefit in your department. Unless you create a benefit, whatever we code is worthless.</li>
<li>Focus on applying in your project your domain knowledge. Only you know it, I don’t.</li>
<li>Here is a (short) list of things you should try in your R-script (most of which you already have). You do not need to push for more complex methods and crazy good programming, what you have is already enough. If something more complex is required later on, I will do it for you.</li>
</ul>
<p>Ehm, exact opposite of what I originally did, right? <strong>Embedded Data Scientist therefore stays in his/her original department and context, and only to a required (limited) extend enhances her knowledge on Data Science, so that he/she can create the value</strong>. He/she possesses edge over (first generation) of Data Scientist in the context knowledge and can hence create more valuable products.</p>
</div>
<div id="value-of-embedded-data-scientist" class="section level2">
<h2><span class="header-section-number">2.7</span> Value of Embedded Data Scientist</h2>
<p>As everyone says it these days - data are everywhere, companies just need to start utilizing them. We can thus take as granted that Data Science will have justification in upcoming years. Though why do companies need Embedded Data Scientists and why they should focus on them instead of the first generation of Data Scientists? Simply because the <strong>growth in created benefit</strong> will be much greater through</p>
<ul>
<li>Possibility of having higher counts of Embedded Data Scientists, as compared to Data Scientists due to the fact that extensive formal education is not required.</li>
<li>Possibility of having more impactful Data Science projects as these will be integrated better to the business, if created by properly trained Embedded Data Scientists.</li>
</ul>
<p>Embedded Data Scientists do know better what needs to be optimized and in which way, because the context (business area) is their origin. Is it necessary then that every Embedded Data Scientist is on the same level of knowledge? Of course not, that is why I will be basing this book on 6 levels of Embedded Data Scientist, which should only achieve a level suitable for his/her involvement in Data Science. So, do you want to become one of them?</p>
<p>What happens with the original (first generation) Data Scientists? We will still need them, just in slightly different roles as until now. They become heavy developers, guarantors and trainers. Whenever a complex problem occurs, which needs a technically challenging solution, it will be them who focus on it. The thing is, that in many organizations, there are only a handful of such problems, that is why this makes sense. Secondly, they act as guarantors of solutions developed by Embedded Data Scientists. This again makes sense, because reading through something and commenting on it takes a fraction of time as compared to developing it. Finally, they should act as trainers as there is a need to train, coach and mentor a <em>lot</em> of Embedded Data Scientists.</p>
</div>
<div id="anyone-can-become-embedded-data-scientist" class="section level2">
<h2><span class="header-section-number">2.8</span> Anyone Can Become Embedded Data Scientist</h2>
<p>I honestly believe that whomever you are, <strong>you can become a Embedded Data Scientist</strong>. Why? Because Data Science methods add up to only about half of the requirements for a success, the other half is context knowledge and application. Thereafter whatever your background is, you can become one and create value to your company. Moreover, there is no single-level of Embedded Data Scientist in my mind, but several of them.</p>
</div>
<div id="the-6-levels-of-embedded-data-scientist" class="section level2">
<h2><span class="header-section-number">2.9</span> The 6 Levels of Embedded Data Scientist</h2>
<p>There are many great courses, programs or coding platforms available online - why should you then read this book in particular? It is because I plan to help you <strong>grow through capabilities, not through skills</strong>. It is actually one of the reasons why I decided to write this book. I see oftentimes learning content structured through skills - Importing Data, Cleaning Data, Preprocessing Data, Basics of Machine Learning; being the most common path out there, sometimes being up to 80 hours long. The issue is that you will most likely be only able to apply yourself once you learned all the skills. That is not good, as Data Science is a lot about practice and connecting to context where you want to apply yourself as a Embedded Data Scientist.</p>
<p>That is why this book sets 6 levels through which you will be growing. With each new level, your capabilities and powers within Data Science will inherently grow and so will your value for projects and employers. This gives you the ultimate opportunity to practice your skills - because you will be able to; in the real world! As you will notice, each level holds its definition and a length required (from my perspective) to reach this level from a previous one.</p>
<p><strong>Level 1: Being Aware</strong><br />
You know what Data Science is about, what it can and cannot achieve. You also know what path lies ahead of you as a Embedded Data Scientist. Learning length: 1 hour</p>
<p><strong>Level 2: Observer</strong><br />
You are able to observe a Data Science project running, without being able to contribute to it. You are though able to make use of the outputs of a Data Science project as well as help with inputs for such projects. If someone presents you a Data Science project, you are able to question its qualities. Learning length: 5 hours</p>
<p><strong>Level 3: Contributor</strong><br />
You are able to assume simple task(s) within the Data Science project, and create a benefit to the project productively - Data Preprocessing, Data Visualisation and Baseline Machine Learning. Learning: 30 hours</p>
<p><strong>Level 4: Modeller</strong><br />
You are able to assume any basic task within a Data Science project and hold responsibility for statistical parts. Learning: 40 hours</p>
<p><strong>Level 5: Project Responsible</strong><br />
You are able to define a Data Science project from scratch and execute it. To do this, you are also able to organize a team around a Data Science project and work with peripheral fields such as Data Engineering. Learning: 40 hours</p>
<p><strong>Level 6: Leader</strong><br />
You are able to grow Data Science initiative in your organization both effectively (hiring) as well as conceptually (specializations). Learning: 40 hours</p>
<p>Each of these levels is very different both from the content perspective, as well as from the desirable approach by you. For example, on a Statistician level, you are going to be focused solely on statistical formulas and their intuition. Be prepared for sitting longer hours, stretching your analytical mind. All of a sudden, this stops and in order to become a Project Responsible, we are going to sharpen your soft skills, such as how to organize a team effectively. It will be needed to free your mind and think about people instead of code.</p>
<blockquote>
<p>This book unfortunately cannot cover <em>all</em> that you should know on each of these levels. What the book intends is to give you <em>all intuition</em> and <em>awareness of concepts</em> which is required on each level.</p>
</blockquote>
<p>The reason why I decided to write this way (not covering concepts through technical details and coding), is that I believe from my experience that once the intuition in the concept is achieved, then it will become rather simple for you to apply it.</p>
</div>
<div id="real-world-experience" class="section level2">
<h2><span class="header-section-number">2.10</span> Real World Experience</h2>
<p>What is the biggest struggle of anyone who would like to become a (Embedded) Data Scientist? To get real world experience and practice. Whatever people claim within their online courses and trainings, the trainer will <strong>never</strong> be able to offer you what is awaiting for you in the real world of Data Science. I don’t even claim it about my training. The only truthful way is hence to go to a real project. Use the <em>6 levels of Embedded Data Scientist</em> exactly for this purpose! Let me show you an example of why I decided to write and teach in this way.</p>
<p>You come to a job interview (external or internal one) and say that you have been learning and would like to become part of this Data Science project. The conversation might go as follows:</p>
<p><em>Interviewer</em>: Great to see your interest. So how can you contribute to our projects and help out?<br />
<em>You</em>: Well, I learned a bit of Python, I am able to put together some basic statistical models and also do some data preprocessing.</p>
<p>Let me stop here for a second and explain to you what is happening behind this scene of this situation, which is happening probably hundreds of times every day. You are having hard time <strong>selling</strong> yourself and interviewer is having hard time <strong>evaluating</strong> your qualities. You are both stuck, due to simple reason - you have listed skills instead of capability to contribute.</p>
<p>Now let’s do a similar conversation and we will reuse one of the levels from above as your answer:</p>
<p><em>Interviewer</em>: Great to see your interest. So how can you contribute to our projects and help out?<br />
<em>You</em>: I am able to act as an “Observer” to your Data Science projects. This means that I cannot directly contribute to its productive code pipeline, but I am able to help out with inputs and outputs. Due to my extensive background in Retail Banking, I know what features might be interesting to collect about customers and used in models and also how to apply outputs of your project in Marketing Campaigns. When a Data Scientist will put together a Machine Learning model, I will be able to do basic evaluation of its qualities.</p>
<p>Do you <em>feel</em> the difference between the two conversations? Instead of talking about skills, you started to talk about a possible contribution which you can do. You also very clearly drew a line of what you cannot do and the Interviewer will have it easier evaluating you. Moreover, you had a space to relate to your previous field - we all have something where we are coming from. This is what really matters for Embedded Data Scientist - show possible contributions that will be impacting the project and benefit out of it directly.</p>
</div>
<div id="learning-without-math" class="section level2">
<h2><span class="header-section-number">2.11</span> Learning Without Math</h2>
<p>Mathematics is undoubtedly the foundation of many fields, Data Science being one of them. If one masters it, incredible beauties will uncover a lot of mathematical formulae and deep understanding of many concepts can be achieved. It has only one problem…“it’s f_____g hard to learn!!!”. I personally know only two kinds of people. First group are ones who are comfortable with math - they liked the subject for many years and have the incredible patience to learn it. Most of the time they also invested into some form of formal education within math. The second group are people who don’t like it and whenever they meet it, they search for <em>intuitions</em> and workarounds just to get the piece of work done. The share of people who belong to the latter group among my friends is 95% and that could be a sad fact for a field like Data Science which would like to grow, while being based heavily on Math. Or is it?</p>
<p>In my perspective, the first generation of Data Scientists are primarily the ones who are fine with maths and the second generation belongs to the non-likers. Now let me tell you, it’s perfectly fine and natural to not like math and not be comfortable with it. Who should adjust? Should it be 95% of the population or teaching methods of Data Science? Let me bet on the latter…</p>
<p>That is why <em>this book will not teach anything through mathematics</em>. I honestly believe that in order to train a Embedded Data Scientist, math is not only un-needed but also un-recommended, based on my argumentation above.</p>
<p>P.S. There will be a few statistical concepts, so don’t blame me if they look like math. As I promised though, there will be no formula, just intuition.</p>
</div>
<div id="population-and-observation" class="section level2">
<h2><span class="header-section-number">2.12</span> Population and Observation</h2>
<p>It is about time we dig into actual learning, not just framing of either this book or Data Science itself. We hop into it by introducing two basic terms: <strong>population and observation</strong>, which I presume do not sound too unfamiliar.</p>
<blockquote>
<p>Popululation is group of all items (or living beings) which are of our interest.</p>
</blockquote>
<p>It is easiest of course to imagine human population; of a city, country, area. These can be of our interest because we might be interested in what impact will a certain new law have. We can be more specific and have smaller human population, such as customer base of a company, whereas this population is interesting as it provides us with revenues. Though population does not have to be living, it can also be a set of items; such as all lightbulbs in a building. We might be interested in which light bulbs will be in need of exchange soon. As you see, it is pretty flexible term. I think you already guessed what an observation is and it needs no detailed clarifications.</p>
<blockquote>
<p>Observation is a single unit (item, living being…) out of the population of our interest.</p>
</blockquote>
<p>Now withing the world of Data Science, there are in general three possible scenarios, which you will be meeting on daily basis.</p>
<ol style="list-style-type: decimal">
<li>We have data about <em>all observations</em> in population of our interest.</li>
<li>We have data only on <em>part of observations</em> in population of our interest.</li>
<li>We want to predict <em>future values</em> about population of our interest.</li>
</ol>
<p>Each of these represent a challenge of different kind, and will be dealt with using different methods. Moreover, often times we will deal with all three scenarios using the <em>same data</em>. Imagine you are a grocery store with a well developed loyalty system. Your customers always show the loyalty card at the cashier to receive a discount, so you have nice and conscise data about essentially all of your customers. Your manager comes to you and says that he would like to optimize the opening hours of the store so that they are more fitting <em>for our current customers</em>. The population in this case will be only our customers, which means that the Data Science challenge will be dealing with data about all customers. This is in fact the easiest of the three options, as we are making <strong>no assumptions</strong>. We know that whatever our findings will be, they will for sure be correct, as we have data about the whole population.</p>
<p>Within a few weeks, the manager comes and says that he would like to know how much people on average spend on groceries in a city where your store is located. The scenario changes, as the population of interest is all of a sudden <em>entire city population</em>. Out of the city, only a small part of the inhabitants are your customers, which means that the data which you have are only for part of observations in a population. This will be a more challenging task, as you will need to <strong>make assumptions</strong>. What if the customers of your store are not like the rest of the city? Maybe your store is focused on low-end price range and it will be tricky to assume that the average customer in a city spends the same amounts for groceries. However much we will try with Data Science, our answer will not be perfectly accurate and correct, yet it might suffice.</p>
<p>After your past two successful projects, manager comes with a big request to you - to predict a future. Based on your managers reasoning, stocking on certain items can be better as your warehouse tends to run out of those. He would like you hence to predict the <em>future purchases of your customer population</em>. Is it even possible? Certainly it is and it has been done long before anyone ever heard of Data Science, Statistics or Machine Learning. Even by a rule of thumb and based on your experience you can make educated guesses about the future. Ice cream is sold the most during the summer time and ginger cookies in the winter. Data Science will only make these predictions of future more accurate, sometimes significantly more accurate.</p>
</div>
<div id="knowing-entire-population" class="section level2">
<h2><span class="header-section-number">2.13</span> Knowing Entire Population</h2>
<p>Out of the three typical Data Science scenarios, possesing data about all observations, is the <em>simplest</em> and most straightforward. Our only goal is simply to describe the population, using the worlds of <strong>Descriptive Statistics</strong> and Data Visualisation. Now, why would we want to <strong>describe</strong> a population? Simply, because we want to <em>understand</em> it and know some <em>information</em> about it. Having in front of you an entire list of goals scored in the last hockey season will not help you determine who was the best player of that season by itself. You will need to search for which players scored the most goals, maybe look even deeper. If someone would show you the weather for the past two years, broken down to individual days, it wouldn’t be exactly easy to estimate what the weather will be tomorrow. We need to somehow <em>aggregate, summarize or describe</em> these populations in order to determine something meaningful.</p>
<div id="mode-median-and-mean" class="section level3">
<h3><span class="header-section-number">2.13.1</span> Mode, Median and Mean</h3>
<p>We can start with the simplest tools of <em>descriptive statistics</em> - <strong>measures of central tendency</strong>. Don’t get scared, the phrase just stands for describing what lies in the middle of the population which we aim to describe. You most likely already applied these tools, by referring to an average. Maybe, sometime in the past you were asked some of these questions:</p>
<ul>
<li>What is usually the weight of loaf of bread sold in shops? (<em>average weight of bread</em>)</li>
<li>What is usually the temperature in your city in summer months? (<em>average temperature in summer</em>)</li>
<li>What is usually a salary in your country? (<em>average salary in a country</em>)</li>
</ul>
<p>Most likely you answered these questions by intuition in your mind. If you would however turn to the world of descriptive statistics, there would be three basic tools available for you to answer them - mode, median and mean.</p>
<p><strong>Mode</strong> is the simplest measure of <em>average</em> of the three. In order to calculate mode, you simply need to look at the <em>most common</em> occurence in your population. This could be a good measure for answering the bread question. We could walk into the shop and observe the weights of loafs offered there such as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loafs_weights_grams &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">500</span>, <span class="dv">500</span>, <span class="dv">400</span>, <span class="dv">1000</span>, <span class="dv">500</span>, <span class="dv">250</span>, <span class="dv">500</span>, <span class="dv">250</span>)</code></pre></div>
<p>Just by looking at the weights, we can easily determine what the mode is - <em>500 grams</em> as this is the most common value. We can verify it by using an R function for calculating mode.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">getMode</span>(loafs_weights_grams)</code></pre></div>
<pre><code>## [1] 500</code></pre>
<p>If you think about the question intuitively, does <em>mode</em> provide us with a satisfactory answer? Most likely yes - usually the loafs weight 500 grams. Unfortunately, mode is not always the best representation of <em>average</em>. We can see it’s incapabilities if we try to answer our second question regarding average temperature in the summer.</p>
<p>The data which we have about summer temperatures are as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">summer_temperatures_celsius &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">35</span>, <span class="dv">35</span>, <span class="dv">32</span>, <span class="dv">28</span>, <span class="dv">31</span>, <span class="dv">25</span>, <span class="dv">26</span>, <span class="dv">27</span>, <span class="dv">24</span>)</code></pre></div>
<p>If we used mode, and picked temperature which is occurring the most times, or in other words is the <em>most common</em>, this would be temperature 35. If we think about it intuitively, is it the best answer? Certainly not! The average temperature by our intuition and looking at the numbers is somewhere below 30. Luckily we have another tool from descriptive statistics at our disposal - median.</p>
<p><strong>Median</strong> is also a rather simple tool, as it simply finds the <em>middle observation</em>. The way we do that is rather straightforward; we sort the observations from smallest to largest and take the one in the middle. Let’s use the R function to sort the temperatures and visually find the middle value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sort</span>(summer_temperatures_celsius)</code></pre></div>
<pre><code>## [1] 24 25 26 27 28 31 32 35 35</code></pre>
<p>As we have 9 values, the median will be the fifth value, in this case 28 degrees. Let’s verify it by using the R function which calculates the median automatically.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">median</span>(summer_temperatures_celsius)</code></pre></div>
<pre><code>## [1] 28</code></pre>
<p>Our visual calcululation was correct. If we think about it intuitively, does the calculated result make sense as an average summer temperature? Indeed it does, the <em>median</em> in this case did better job than <em>mode</em>. As you see, it depends on our population which of the two does a better job. Will median help us with our third question of providing <em>average salary</em> though?</p>
<p>Here is our data regarding salaries in the country. They are already sorted from smallest to largest for simplicity.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">salaries_country &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">350</span>, <span class="dv">400</span>, <span class="dv">450</span>, <span class="dv">470</span>, <span class="dv">500</span>, <span class="dv">520</span>, <span class="dv">1200</span>, <span class="dv">1270</span>, <span class="dv">1300</span>, <span class="dv">1460</span>, <span class="dv">1500</span>)</code></pre></div>
<p>If we now calculate the median:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">median</span>(salaries_country)</code></pre></div>
<pre><code>## [1] 520</code></pre>
<p>The answer does not seem perfectly representative from our intuition. Yes, indeed the middle value calculated by median is 520, but it does not quite grasp the salaries which are above 1000. Luckily, we have our final tool among measures of central tendency - mean.</p>
<p><strong>Mean</strong> is a bit more tricky to calculate. By calculating mean, we find a <em>point in the exact middle of our points</em> regardless of how our salaries look like. The calculation is straightforward:</p>
<blockquote>
<p>To calculate <em>mean</em>, sum all the points and then divide the result by their count.</p>
</blockquote>
<p>That is not so bad, we could do it with a calculator or even on the back of an envelope. Firstly, let’s get the sum of all observations:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">350</span> <span class="op">+</span><span class="st"> </span><span class="dv">400</span> <span class="op">+</span><span class="st"> </span><span class="dv">450</span> <span class="op">+</span><span class="st"> </span><span class="dv">470</span> <span class="op">+</span><span class="st"> </span><span class="dv">500</span> <span class="op">+</span><span class="st"> </span><span class="dv">520</span> <span class="op">+</span><span class="st"> </span><span class="dv">1200</span> <span class="op">+</span><span class="st"> </span><span class="dv">1270</span> <span class="op">+</span><span class="st"> </span><span class="dv">1300</span> <span class="op">+</span><span class="st"> </span><span class="dv">1460</span> <span class="op">+</span><span class="st"> </span><span class="dv">1500</span></code></pre></div>
<pre><code>## [1] 9420</code></pre>
<p>We can count the points (salaries) just visually and know that there are 11 salaries provided. We can then do a final calculation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">9420</span> <span class="op">/</span><span class="st"> </span><span class="dv">11</span></code></pre></div>
<pre><code>## [1] 856.3636</code></pre>
<p>And finally we can verify this result by calling an R function which calculates the mean.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(salaries_country)</code></pre></div>
<pre><code>## [1] 856.3636</code></pre>
<p>The mean of approximately 856 seems a more reasonable result compared to a median of 520, to represent an <em>average salary</em> in this case.</p>
<p>As you see, neither of the three measures of central tendency is a silver bullet. Their success depends largely on a population which we are trying to describe. That is why it might be a good idea to look at all three of these and then face the provided answers with our intuition.</p>
<p>The three measures - mode, median and mean; are actually not the most important piece of learning now. The fact, that we know our did our very <strong>first application of Data Science</strong> is! We started the chapter by saying that the aim of Data Science is to create valuable information out of the data, whereas this information has value for someone (our employer). Maybe we are working for a bread producer and our task is to find out how the producers can differentiate in the market - now we know that it should not be 500 grams bread. Maybe our employer is a sunscreen manufacturer and wants to figure out for which temperatures the sunscreen should be optimized - now we know that 28 degrees. Or maybe, our employer is the government trying to figure out which income groups should pay lower taxes - could be somewhere below 856 Euro.</p>
</div>
</div>
<div id="not-knowing-entire-population" class="section level2">
<h2><span class="header-section-number">2.14</span> Not Knowing Entire Population</h2>
<p>If we have data only about part of population of our interest, we will introduce a special term for these observations - <strong>sample</strong>. As we have already discussed, the important thing for us is to not only understand the sample, but entire population to which this sample belongs. What will be very important for us, as Data Scientists, will be a specific characteristic of the sample called <strong>representativeness</strong>. In other words, we care about how well the sample represents the rest of the population.</p>
<p>Imagine you are running a bookstore and you are interested in how many books on average people in the country read per year. The sample which you have avilable are your customers - how many come every day and how many books they purchase. If we only cared about our customer base, we would turn back into the world of Descriptive Statistics and by using measure such as median, we would be done with the task quickly. The challenge ahead of us is different though - our customer base is just a small sample our of entire population of the country! Is our sample <em>representative</em>? We are very unfortunate as it probably is not. In fact the observations in our sample might be the only people in the country who are reading books (if we are the only bookstore) and the rest of the population does not read at all. This means that due to low <em>representativeness</em> of our sample, drawing conclusions about entire country population might be very hard.</p>
<p>We were tasked with collecting information about how the local elections for city major will end, as there are two candidates. We can in this case even decide to <strong>construct a sample</strong>, which is in fact in many similar studies done. This small field of Data Science is in fact an art in itself. We need to take into account many factors. For example, we decide that we are going to ask people on the street, next to the bus stop, who they will vote for. We believe that if we ask 1000 people who pass by, our sample will be representative enough to draw conclusions about entire city with 30000 inhatitants. There is a problem though, which is that our sample will be underrepresentative for people who <em>do not use bus</em>. If you think about it, indeed they were not even given a chance to answer our survey as they were in the car. Older people who were on that day inside their house were also not given a chance to answer your question about whom they will vote for. As you see, it is <strong>not easy to have or construct truly representative sample</strong>.</p>
<p>If we are lucky enough and have representative sample, or great enough with our sample design and obtain representative sample, we will turn into a wonderful world of <strong>Inferential Statistics</strong>. The name comes from a fact that unlike before when our task was to describe a population, now we will try to <strong>infere</strong> information about the population based on our sample.</p>
<div id="confidence-interval" class="section level3">
<h3><span class="header-section-number">2.14.1</span> Confidence Interval</h3>
<p>Add an example of using this method through confidence intervals.</p>
</div>
</div>
<div id="predicting-future-unforeseen-values" class="section level2">
<h2><span class="header-section-number">2.15</span> Predicting Future &amp; Unforeseen Values</h2>
<div id="predicting-future-values" class="section level3">
<h3><span class="header-section-number">2.15.1</span> Predicting Future Values</h3>
<p>Are we some sort of fortune tellers with a glass ball claiming that we are able to predict a future? Fortunately not, we are relying on a simple understanding of our nature, depicted on a picture below. Data Scientists believe that many phenomena (such as purchases in our grocery store) are through certain nature’s <strong>mapping function</strong> connected to inputs (such as weather). Our outcome which we are interested in predicting will then be determined by the inputs to such a large degree, that we will be able to predict the outcome. Let me slow down a bit.</p>
<div class="figure"><span id="fig:nature-process-1"></span>
<img src="resources/01-being-aware/nature-process-1.jpg" alt="Simplified idea of why Data Scientists believe they are able to predict future values."  />
<p class="caption">
Figure 2.4: Simplified idea of why Data Scientists believe they are able to predict future values.
</p>
</div>
<p>Think about yourself and your desire to purchase an ice cream. Is it completely <em>random</em> process which is not influenced by anything whether you will go and buy an ice cream? I am pretty sure that is is not. If the weather is warm, if your partner says that he/she would like an ice cream or if you just saw glorious ice cream commercial, you might be more likely to go out and purchase the ice cream. Similarly, there are factors which can negatively influence you and you will be less likely to go, such as you being determined on a diet or you feeling a bit of inflammation in your throat. Inside of your mind, is this <em>function</em> designed by nature which takes into account all of these positive and negative factors and then lead to a decision whether you will go and purchase the ice cream or not.</p>
<p>Data Scientists’ job is then to <strong>estimate this function</strong> (or approximate it). They will want to construct the algorithm, base don which they will have as accurate mapping of inputs to the output. How accurate their predictions will be is then dependent on two primary aspects:</p>
<ol style="list-style-type: decimal">
<li>How complex the mapping function is.</li>
<li>How many of the significant inputs are they able to grasp and collect data about.</li>
</ol>
<p>The future prediction of Data Science will never be perfectly accurate. There will always be at least a small amount of <strong>error</strong>, which can be cause by one of the two aspects mentioned above. 9 out of 10 people will in the summer in a good weather purchase an ice cream when walking with their dog through the city. The 10th person will not decide to do so, as she is lactose sensitive, and you are offering only lactose based ice cream. In this case, Data Science missed one significant input; but that is perfectly fine isnt’t it? We are able to correctly predict 9 out of 10 cases.</p>
</div>
<div id="correlation-vs-causality" class="section level3">
<h3><span class="header-section-number">2.15.2</span> Correlation vs Causality</h3>
<p>In the 1990s, in some smaller cities in Germany a strange phenomena was observed. At the same time, larger numbers of storks started to occur in the city. Moreover, a lot of babies were being born. It is unclear whether the story of “Storks bring babies” occured here, or it was present before, neverthless people started to believe it. Storks coming to the city must have been bringing all the new babies which were being born.</p>
<div class="figure"><span id="fig:storks-babies"></span>
<img src="resources/01-being-aware/storks-babies.jpg" alt="Do storks bring babies? Picture by Pixabay on Pexels."  />
<p class="caption">
Figure 2.5: Do storks bring babies? Picture by Pixabay on Pexels.
</p>
</div>
<p>If we would use our newly gained knowledge on Data Science being able to predict the future, the picture below depicts how would the relationship look like. Nature supposedly gave us a <em>mapping function</em> where the input is storks coming to the city and the output is babies being born. This would mean that storks <strong>cause</strong> babies being born. This would be a phenomena called <strong>causation</strong>.</p>
<div class="figure"><span id="fig:nature-process-2"></span>
<img src="resources/01-being-aware/nature-process-2.jpg" alt="Belief which many people had - storks coming to the city *cause* more babies to be born."  />
<p class="caption">
Figure 2.6: Belief which many people had - storks coming to the city <em>cause</em> more babies to be born.
</p>
</div>
<p>Quite a few scientists (as well as Data Scientists) were intrigued by this phenomena and whether it is the truth. Upon observation of the cities in the upcoming years, they revealed a surprising pattern. Storks <strong>do not cause</strong> babies to be born. The process is a bit more complicated. In fact, it was found out that a lot of young couples were moving into the cities from rural areas. These young couples upon settling down in house, decided to have a baby. As you see, babies come first. Now what do the storks have to do with it? Storks like to set their nests on the roof of houses. As these young couples moved into the cities and built houses for themselves, storks simply had a lot of new houses on which they can comfortably build their nests.</p>
<p>What this means is that the <strong>causation does not exist</strong>. What exists though is <strong>correlation</strong>. Correlation is a term for when two things tend to happen, or occur at the same time. The case of storks and babies in German cities in 1990s was a perfect example of correlation. That is why we need to redraw our view of nature’s function.</p>
<div class="figure"><span id="fig:nature-process-3"></span>
<img src="resources/01-being-aware/nature-process-3.jpg" alt="Storks do not cause more babies being born. Hence only correlation occured, not a causation."  />
<p class="caption">
Figure 2.7: Storks do not cause more babies being born. Hence only correlation occured, not a causation.
</p>
</div>
<p>What you should take from this story is that sometimes Data Science does not find a <em>mapping function</em> which depicts a <em>cause</em>, but only a mapping functions which depicts <em>correlation</em>. If we would come back to our ice cream purchase example when Data Scientist believes that warm weather will make you go and buy an ice-cream, this function approximation can work and will be accurate. It however does not mean that warm weather <em>causes</em> you to go and buy an ice cream. The truth might be that what caused you buy an ice cream was that you watched a weather forecast in the morning where they said that it is going to be a hot day today. Even though the <em>mapping function</em> which Data Scientist approximated works and correctly predicts that you will go and buy an ice cream, it might only be a correlation which causes the function to be accurate.</p>
</div>
<div id="predicting-unforeseen-values" class="section level3">
<h3><span class="header-section-number">2.15.3</span> Predicting Unforeseen Values</h3>
<p>This book is being written at a time of a coronavirus crisis, so let’s take an example which is nowadays very pressing. Imagine you are a company whose employees still have to come to the office. You are being worried whether they comply with all the recommendations such as washing hands and wearing face cover.</p>
<p>If you would like to set up a camera which would be recognising whether people wear face cover, it would be rather easy if every person looked the same and were in the same position. Then the computer would always look at the very same pixels and confirm whether you wear a face mask or you don’t. Unfortunately for our Data Science project, every person is <strong>different</strong> - everyone is of different height, will be of different posture, has different colour of face cover. This <em>difference</em> and <em>variance</em> means that our algorithm for recognising face cover will have to correctly classify also previously unforseen values. In other words, when we will be training the algorithm, we will not be able to show it all possibilities which might arise in the future.</p>
</div>
<div id="association-rules" class="section level3">
<h3><span class="header-section-number">2.15.4</span> Association Rules</h3>
<p>Add an example of association rules.</p>
</div>
</div>
<div id="level-1-being-aware---reached" class="section level2">
<h2><span class="header-section-number">2.16</span> Level 1: Being Aware - Reached</h2>
<p>Congratulations! Without even realizing it, you have reached the first level which I call “Being Aware”. You are now aware of what Data Science is, what it isn’t, what it struggles with and what is the role of Embedded Data Scientist. Here are some key takeaways which you should have from this chapter:</p>
<ol style="list-style-type: decimal">
<li>Remember the five cornerstones upon which this book is built. If you plan on continuing reading it, these will be helpful to keep in mind.</li>
<li>Data Science is an art of creating valuable information out of data.</li>
<li>No training or online course can really prepare you for the real world. Hopefully this book will help you to go to the field as soon as possible and apply yourself, based on a level which you reached.</li>
<li>Data Science deals usually with 3 scenarios depending on the population which is of our interest.</li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="observer.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["intuitive-ds-book.pdf", "intuitive-ds-book.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
