# Being Aware {#being-aware}

## Five Cornerstones

You will quickly notice that this book is structured quite differently compared to other offerings on the market. Let me reason about that, even before I introduce you to the structure and the transformation that this book offers. I have been a lecturer/trainer for a few years and I always notice that content does not matter as much as the *path through the content* as well as the *assumptions upon which the content is built*. Only if both of these are fine, the book/course/training can offer you (the reader/student) a **transformation** - taking you from where you are, to where you want to be. In this case I am hoping you would like to make a living within Data Science or create some amazing project within it!

This book is hence built on five cornerstones:  

* Data Science is a practice of using data to create a direct benefit.  
* Embedded Data Scientist is becoming a crucial occupation.  
* Anyone can become a Embedded Data Scientist.  
* There are 6 levels of Embedded Data Scientist and these should act as a learning curve.  
* Math is not required as a teaching tool in order to train a Embedded Data Scientist and can be replaced by visualisation and intuition.  

Did I go crazy claiming that anyone can become a Data Scientist? And what about the Math which is appraised by everyone as the crucial tool within data science?!? Maybe I have, but these cornerstones (assumptions) worked for me as well as for my students within the past years. Let me in this chapter explain **why** I believe that these things might work out for you.

## Defining Data Science

The very first thing that I would like to do is to answer a simple question: *What is data and what is information?* The difference between the two is in their value. **Data** inherently do not have any value for their owner, simply because he/she cannot do anything beneficial upon them. On the other hand, **information** can be valuable for its owner. These two are however thinly connected - as *information* is derived from *data*, while this process is called **Data Science**. I will give you an example from my recent past on how I got a value out of Data Science.  

I was always interested in my sleep, as I know that in order to live a happy life, I shall sleep well. The only two things I know really is how long I sleep and how do I feel in the morning. I then found an app on my phone which was promising to analyze my sleep and give me recommendations on how to improve my sleep. The app is using an accelerometer in my phone, recording my movements at night. During the first two nights, the app only collected *data* - every morning I was able to see various graphs on how I slept. After a week though, recommendations came such as "when you go to bed late, around 23:00, even if you sleep full 8 hours, your sleep quality suffers.". This is already *information* which had a value for me. The app is Data Science *process* of creating valuable information from data.  

If you now turn to search engines and start to search for Data Science terms, you will be overwhelmed by articles and (unfortunately) buzzwords - Machine Learning, Data Mining, Artificial Intelligence, Tensorflow, R, Python. These are either tools of Data Science or neighbouring fields. Do not get confused or overwhelmed by these. The book which you are reading is a way to master these methods, but first I want you to truly and deeply understand the crucial ideas of Data Science. This might actually be the most important message from this book - always keep in mind that the methods should always serve the purpose which Data Science has.

>Data Science is merely an art of turning data into information, which creates benefit.

Sounds like a vague definition right? Indeed it is, and it acts as double edged sword. On one hand, there are vast applications for Data Scientists along with possible specializations. On the other hand, as the field is not strictly defined it causes problems not only to newcomers but even to experienced professionals, with knowing what *skillset* they even should have and what *methods* should they consider and learn. Take a look at following graph:

```{r data-mining-Venn-diagram, echo = FALSE, fig.cap='Overview of various fields in Data Science (Data Mining) as depicted by SAS Institute.'}
knitr::include_graphics("resources/01-being-aware/data-mining-Venn-diagram.png")
```

The picture depicts overview and overlaps of various *disciplines* within Data Science, previously more recognized as Data Mining. I think that as part of the definition of Data Science, it is necessary to take closer look at these disciplines, as some are ancient predecessors which gave birth to our wonderful field nowadays, while some are rather novel and were connected to it only recently.

## Disciplines of Data Science

**Statistics** can be certainly named as the most crucial and oldest predessor of Data Science. Moreover, when students start to learn Data Science, they are often recommended to start with Statistics. There is a good reason for it - Statistics comprises a very heart of the field as you will learn soon, through terms such as Descriptive Statistics and Inferential Statistics. Practitioners of Statistics have been for more than two centuries interested in deriving valuable information out of data. Earliest examples include a lot of demographics data, such as population census. Yet, I would like you as reader kindly ask you to not fixate your mind on Statistics, as many other disciplines are of crucial importance.  

**Databases**, as you will learn are a purposed collections of data. Companies have been for decades deciding to create databases of their products, customers, equipment and many more. Databses have to be not only created, but also maintained and curated. Without access to the data at the end of the day, we are hardly going to create any valuable information. We are going to dig a little into this field in later chapters of this book and you will get even *data engineering* knowledge.

**Knowledge Discovery in Data (KDD) and Data Mining** started to occur as disciplines simply because databases existed, and companies wanted to derive the value out of them. Imagine you have a database about sales of your products. Why now use some tools from Statistics to gain more knowledge about your business? And so the origins of Data Mining arose - the art of mining jewels out of the mountains made up of data. In fact, if someone asked me what is the difference between Data Mining and Data Science, I would say that these two are pretty *close to each other*. The tipping point of when Data Science became predominant was when Machine Learning came into scene, as you can see from Google Trends.

```{r data-mining-data-science, echo = FALSE, fig.cap='Popularity comparison of three terms - Data Mining, Data Science and Machine Learning. Picture from Google Trends.'}
knitr::include_graphics("resources/01-being-aware/data-mining-data-science.jpg")
```

**Machine Learning** is a discipline within which we are letting machines learn based on the data. We are going to deal with this topic a lot in later chapters, as it comprises a large part of Data Science nowadays for a simple reason. As it turns out, if we let a machine learn based on some historical data (i.e. product sales) it might be able to discover powerful patterns (i.e. if a customer buys product A, recommend him product B as he is likely to purchase it). The reason why we let machines learn, instead of trying to find patterns ourselves (such as through Statistics) is simply because often times they can be more powerful than us, humans. If we let machine and 3 year-old baby compete at recognising cats at pictures, the child be fine with competing. If we however let even doctor compete at identifying signs of diabetic retinopathy in eye images, it will already be probably unfair fight. Moreover, machine will be able to do identifications significantly faster.  

Machine Learning is then what connects Data Science to **Artificial Intelligence**. This last field might be probably the most complex as it not only works with data and information; but also with automation, robotics and creation of intelligent systems. I think it is the easiest to imagine how these three fields; Data Science, Machine Learning and Artificial Intelligence work together is by looking at humanoid robot Pepper. This cute and handy robot can move around your house and help you with various things. In order to do so, it collects and processes various data from surrounding environment (Data Science), makes sense out of these with learned models (Machine Learning) and puts it together to an intelligent humanoid machine (Artificial Intelligence).

```{r pepper-robot, echo = FALSE, fig.cap='Humanoid robot Pepper as a great example where fields of Data Science, Machine Learning and Artificial Intelligence overlap.'}
knitr::include_graphics("resources/01-being-aware/pepper-robot.jpg")
```

## Defining Data Scientist

Now that we know what Data Science is, it is quite easy to define who a Data Scientist is. He/She is a practitioner of this field, who uses its disciplines(methods to achieve its goal. Usually, a Data Scientist has general education in three areas - Programming, Mathematics and Statistics. Notice that none of these areas deal with *context* or *domain* such as Banking, Medicine or Engineering. Thus Data Scientist - by definition, should be *domain-agnostic*. We can see this also in the definition within Oxford Dictionary:

> a person employed to analyse and interpret complex digital data, such as the usage statistics of a website, especially in order to assist a business in its decision-making

He/she should be able to join any of the mentioned domains, and many more, apply the methods of Data Science to fulfill the goal of creating value, through information, out of data. This is a very important point for you as you will now see.

## The Struggle of Data Science

Now that you heard about Data Scientists, who are Embedded Data Scientists? I think they are the most crucial occupations in the future of the field of Data Science. You heard me right, not the original Data Scientists, but the new generation of Embedded Data Scientists. Let me show you why.  

Data Science as a field has been around for decades in one form or another. There have been market analysts, risk modellers, product developers, artificial intelligence developers and so on. If we however relate to the definition of Data Science above in a way that a Data Scientist can essentially come to any company and make use of its data to create benefit, we can go back to the millenia breakthrough. Universities start to offer programs with names like "Data Analysis", "Business Intelligence'' and first candidates are leaving these programs. It feels like the field is growing tremendously - growth in GPU powers, Deep Learning, Automated Machine Learning products. Especially since the 2010s, job advertisements revolving around Data Science are exploding! Though is the field really growing from the perspective of the market? I would say very slowly, simply because the *created benefit for companies (and their customers)* is growing slowly.  

This is caused by the fact that the field is still relying on the slow and linear growth of the first generation of Data Scientists - ones having formal education, being able to guarantee the work. Now two scenarios can occur when a company attempts to create benefit/profit through data science:

1. It hires *actual* Data Scientists, whereas costs to hire them are tremendous and what is even more expensive is to make them productive. Finding for them process which can be optimized through their methods and then properly optimizing it is lengthy and costly. As these are domain-agnostic, the company needs to also educate them and integrate them into contexts. Company slowly loses interest and stops believing that actual profit in a decent scale can be created this way.
2. It does not hire *actual* Data Scientists, as they are expensive and scarce. People who come to the company have been originally trained in other areas and are now expected to be *actual* Data Scientists. The company has just thrown away a lot of their potential as only their recently acquired experience are counted and not their original context. The hirees are now pushed equally hard as the *actual* Data Scientists and are struggling to create valuable products. Company slowly looses interest and stops believing that actual profit in decent scale can be created this way.

You might now disagree with me and say I am too much of a negativist. To justify my thinking in your mind, let me ask you only one question. As employees, we are expected to create larger profits than what we cost our employer. How many data scientists you know, who can prove that they are repeatedly creating profit for their companies? Not so many, right? Thereafter I believe that the above described struggle holds.

## Who is Embedded Data Scientist

I believe that the answer to this struggle of many companies is recognition of a Embedded Data Scientist (the ones coming in point 2 above) and definition of their relationship to Data Scientists. The market is begging us to do so and we can see it by who comes to job interviews when we make an advertisement for a position of a Data Scientist. These are people who do not have formal education or direct experience. Let me tell you one story from my past.  

I worked in a large organization with thousands of employees as a Data Scientist. Out of nowhere, I received an email from a colleague I never heard of before. She claimed that she is really passionate about the methods of predictive modelling and Data Science and is eager to apply these methods in her CRM department. We met and she showed me R-script in which she tried a bunch of Machine Learning algorithms and preprocessing methods. What I did in turn was that I encouraged her to continue with the passion because the field has a future and I advised her about further methods she can try.  

Only years later, I realized my mistakes in that meeting and that I met one of the first Embedded Data Scientists. I then learned that she left the company as she never managed to get her passion for productive work. I was one of the reasons why she churned because I gave her advice on how to become the first generation Data Scientist, not the second generation of Embedded Data Scientist. Let's look at the definition by Gartner in 2016 of Citizen Data Scientist:  

>Citizen data science bridges the gap between mainstream self-service data discovery by business users and the advanced analytics techniques of data scientists.

This colleague of mine was originally in the first part of definition (business user), while I was in the second part of it (advanced analytics). She was trying to become a bridge between the two, without even realising it! Unfortunately I am only smarter years later and when the same situation happens these days, I react in a different way. Also, the company which I work for now is smarter and allows for an environment where Embedded Data Scientists are given space.

She had something that I could never have - expertise in her CRM department and if I was about to give her advice now it would be:

- Focus on how a predictive model will create benefit in your department. Unless you create a benefit, whatever we code is worthless.
- Focus on applying in your project your domain knowledge. Only you know it, I don't.
- Here is a (short) list of things you should try in your R-script (most of which you already have). You do not need to push for more complex methods and crazy good programming, what you have is already enough. If something more complex is required later on, I will do it for you.

Ehm, exact opposite of what I originally did, right? **Embedded Data Scientist therefore stays in his/her original department and context, and only to a required (limited) extend enhances her knowledge on Data Science, so that he/she can create the value**. He/she possesses edge over (first generation) of Data Scientist in the context knowledge and can hence create more valuable products.  

## Value of Embedded Data Scientist

As everyone says it these days - data are everywhere, companies just need to start utilizing them. We can thus take as granted that Data Science will have justification in upcoming years. Though why do companies need Embedded Data Scientists and why they should focus on them instead of the first generation of Data Scientists? Simply because the **growth in created benefit** will be much greater through

- Possibility of having higher counts of Embedded Data Scientists, as compared to Data Scientists due to the fact that extensive formal education is not required.
- Possibility of having more impactful Data Science projects as these will be integrated better to the business, if created by properly trained Embedded Data Scientists.

Embedded Data Scientists do know better what needs to be optimized and in which way, because the context (business area) is their origin. Is it necessary then that every Embedded Data Scientist is on the same level of knowledge? Of course not, that is why I will be basing this book on 6 levels of Embedded Data Scientist, which should only achieve a level suitable for his/her involvement in Data Science. So, do you want to become one of them?  

What happens with the original (first generation) Data Scientists? We will still need them, just in slightly different roles as until now. They become heavy developers, guarantors and trainers. Whenever a complex problem occurs, which needs a technically challenging solution, it will be them who focus on it. The thing is, that in many organizations, there are only a handful of such problems, that is why this makes sense. Secondly, they act as guarantors of solutions developed by Embedded Data Scientists. This again makes sense, because reading through something and commenting on it takes a fraction of time as compared to developing it. Finally, they should act as trainers as there is a need to train, coach and mentor a *lot* of Embedded Data Scientists. 

## Anyone Can Become Embedded Data Scientist

I honestly believe that whomever you are, **you can become a Embedded Data Scientist**. Why? Because Data Science methods add up to only about half of the requirements for a success, the other half is context knowledge and application. Thereafter whatever your background is, you can become one and create value to your company. Moreover, there is no single-level of Embedded Data Scientist in my mind, but several of them.

## The 6 Levels of Embedded Data Scientist

There are many great courses, programs or coding platforms available online - why should you then read this book in particular? It is because I plan to help you **grow through capabilities, not through skills**. It is actually one of the reasons why I decided to write this book. I see oftentimes learning content structured through skills - Importing Data, Cleaning Data, Preprocessing Data, Basics of Machine Learning; being the most common path out there, sometimes being up to 80 hours long. The issue is that you will most likely be only able to apply yourself once you learned all the skills. That is not good, as Data Science is a lot about practice and connecting to context where you want to apply yourself as a Embedded Data Scientist.  

That is why this book sets 6 levels through which you will be growing. With each new level, your capabilities and powers within Data Science will inherently grow and so will your value for projects and employers. This gives you the ultimate opportunity to practice your skills - because you will be able to; in the real world! As you will notice, each level holds its definition and a length required (from my perspective) to reach this level from a previous one.

**Level 1: Being Aware**  
You know what Data Science is about, what it can and cannot achieve. You also know what path lies ahead of you as a Embedded Data Scientist. Learning length: 1 hour

**Level 2: Observer**  
You are able to observe a Data Science project running, without being able to contribute to it. You are though able to make use of the outputs of a Data Science project as well as help with inputs for such projects. If someone presents you a Data Science project, you are able to question its qualities. Learning length: 5 hours

**Level 3: Contributor**  
You are able to assume simple task(s) within the Data Science project, and create a benefit to the project productively - Data Preprocessing, Data Visualisation and Baseline Machine Learning. Learning: 30 hours

**Level 4: Modeller**  
You are able to assume any basic task within a Data Science project and hold responsibility for statistical parts. Learning: 40 hours

**Level 5: Project Responsible**  
You are able to define a Data Science project from scratch and execute it. To do this, you are also able to organize a team around a Data Science project and work with peripheral fields such as Data Engineering. Learning: 40 hours

**Level 6: Leader**  
You are able to grow Data Science initiative in your organization both effectively (hiring) as well as conceptually (specializations). Learning: 40 hours

Each of these levels is very different both from the content perspective, as well as from the desirable approach by you. For example, on a Statistician level, you are going to be focused solely on statistical formulas and their intuition. Be prepared for sitting longer hours, stretching your analytical mind. All of a sudden, this stops and in order to become a Project Responsible, we are going to sharpen your soft skills, such as how to organize a team effectively. It will be needed to free your mind and think about people instead of code.  

> This book unfortunately cannot cover *all* that you should know on each of these levels. What the book intends is to give you *all intuition* and *awareness of concepts* which is required on each level.

The reason why I decided to write this way (not covering concepts through technical details and coding), is that I believe from my experience that once the intuition in the concept is achieved, then it will become rather simple for you to apply it.

## Real World Experience

What is the biggest struggle of anyone who would like to become a (Embedded) Data Scientist? To get real world experience and practice. Whatever people claim within their online courses and trainings, the trainer will **never** be able to offer you what is awaiting for you in the real world of Data Science. I don't even claim it about my training. The only truthful way is hence to go to a real project. Use the *6 levels of Embedded Data Scientist* exactly for this purpose! Let me show you an example of why I decided to write and teach in this way.  

You come to a job interview (external or internal one) and say that you have been learning and would like to become part of this Data Science project. The conversation might go as follows:  

*Interviewer*: Great to see your interest. So how can you contribute to our projects and help out?  
*You*: Well, I learned a bit of Python, I am able to put together some basic statistical models and also do some data preprocessing.

Let me stop here for a second and explain to you what is happening behind this scene of this situation, which is happening probably hundreds of times every day. You are having hard time **selling** yourself and interviewer is having hard time **evaluating** your qualities. You are both stuck, due to simple reason - you have listed skills instead of capability to contribute. 

Now let's do a similar conversation and we will reuse one of the levels from above as your answer:

*Interviewer*: Great to see your interest. So how can you contribute to our projects and help out?  
*You*: I am able to act as an "Observer" to your Data Science projects. This means that I cannot directly contribute to its productive code pipeline, but I am able to help out with inputs and outputs. Due to my extensive background in Retail Banking, I know what features might be interesting to collect about customers and used in models and also how to apply outputs of your project in Marketing Campaigns. When a Data Scientist will put together a Machine Learning model, I will be able to do basic evaluation of its qualities.

Do you *feel* the difference between the two conversations? Instead of talking about skills, you started to talk about a possible contribution which you can do. You also very clearly drew a line of what you cannot do and the Interviewer will have it easier evaluating you. Moreover, you had a space to relate to your previous field - we all have something where we are coming from. This is what really matters for Embedded Data Scientist - show possible contributions that will be impacting the project and benefit out of it directly.

## Learning Without Math

Mathematics is undoubtedly the foundation of many fields, Data Science being one of them. If one masters it, incredible beauties will uncover a lot of mathematical formulae and deep understanding of many concepts can be achieved. It has only one problem..."it's f_____g hard to learn!!!". I personally know only two kinds of people. First group are ones who are comfortable with math - they liked the subject for many years and have the incredible patience to learn it. Most of the time they also invested into some form of formal education within math. The second group are people who don't like it and whenever they meet it, they search for *intuitions* and workarounds just to get the piece of work done. The share of people who belong to the latter group among my friends is 95% and that could be a sad fact for a field like Data Science which would like to grow, while being based heavily on Math. Or is it?    

In my perspective, the first generation of Data Scientists are primarily the ones who are fine with maths and the second generation belongs to the non-likers. Now let me tell you, it's perfectly fine and natural to not like math and not be comfortable with it. Who should adjust? Should it be 95% of the population or teaching methods of Data Science? Let me bet on the latter...  

That is why *this book will not teach anything through mathematics*. I honestly believe that in order to train a Embedded Data Scientist, math is not only un-needed but also un-recommended, based on my argumentation above. 

P.S. There will be a few statistical concepts, so don't blame me if they look like math. As I promised though, there will be no formula, just intuition.

## Population and Observation

Population is of our interest, not an entire world population (which probably does not interest us).

There are two major possibilities:

**We have data about all observations in population of our interest**. In this case, it is sufficient often times to turn to a simple world of descriptive statistics. If we desribe all observations, our conclusion will be certainly correct (assuming we have don unbiased Data Science). Other tools migh include data visualization or data analysis. The value here comes by being able to act on this population which we are describing.

**We have data only on part of our observations in population of our interest**. In this case, we are turning to the world of inferential statistics often times. We are making assumptions and drawing conclusions about the rest of population based on our sample. Here we can have also a situation that the part of observations that we do not have knowledge of lies in the *future*. This could be an example of new customers coming in the future, or our population simply changing every month or so. The value here comes in ability to act on the unknown part of the population, or to act accordingly with respect to what will happen in the future. 

## Knowing Entire Population

We have already talked about a lot of things, but we have not started with fulfilling of the promise of Data Science, that is turning data into valuable information. There are quite a few ways how this can be done, and these will inevitably be one of the backbones of the book you started to read. We start by the simples, yet often times most efficient way which is **understanding a population**. In fact, if you are able to only describe a population, you already have tremendous powers for Data Science, called *descriptive statistics*. 

We can start by defining a **population**; which is in essence a synonym to a *set of individual points*. Population usually refers to living organisms such as people, animals or other living organisms. But as these living organisms are from statistical point of view just *sets of individual points* it can be anything else - fleet of buses, set of marketing campaigns or batch of machinery.  

Now, why would we want to **describe** a population? Simply, because we want to *understand* it and know some *information* about it. Having in front of you an entire list of goals scored in the last hockey season will not help you determine who was the best player of that season by itself. You will need to search for which players scored the most goals, maybe look even deeper. If someone would show you the weather for the past two years, broken down to individual days, it wouldn't be exactly easy to estimate what the weather will be tomorrow. We need to somehow *aggregate, summarize or describe* these populations in order to determine something meaningful.

## Mode, Median and Mean

We can start with the simplest tools of *descriptive statistics* - **measures of central tendency**. Don't get scared, the phrase just stands for describing what lies in the middle of the population which we aim to describe. You most likely already applied these tools, by referring to an average. Maybe, sometime in the past you were asked some of these questions:

- What is usually the weight of loaf of bread sold in shops? (*average weight of bread*)
- What is usually the temperature in your city in summer months? (*average temperature in summer*)
- What is usually a salary in your country? (*average salary in a country*)

Most likely you answered these questions by intuition in your mind. If you would however turn to the world of descriptive statistics, there would be three basic tools available for you to answer them - mode, median and mean.

**Mode** is the simplest measure of *average* of the three. In order to calculate mode, you simply need to look at the *most common* occurence in your population. This could be a good measure for answering the bread question. We could walk into the shop and observe the weights of loafs offered there such as follows:

```{r loafs_weights_grams}
loafs_weights_grams <- c(500, 500, 400, 1000, 500, 250, 500, 250)
```

Just by looking at the weights, we can easily determine what the mode is - *500 grams* as this is the most common value. We can verify it by using an R function for calculating mode.

```{r getMode, include=FALSE}
# Create the function.
getMode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
```

```{r use_getMode}
getMode(loafs_weights_grams)
```

If you think about the question intuitively, does *mode* provide us with a satisfactory answer? Most likely yes - usually the loafs weight 500 grams. Unfortunately, mode is not always the best representation of *average*. We can see it's incapabilities if we try to answer our second question regarding average temperature in the summer.  

The data which we have about summer temperatures are as follows:

```{r summer_temperatures_celsius}
summer_temperatures_celsius <- c(35, 35, 32, 28, 31, 25, 26, 27, 24)
```

If we used mode, and picked temperature which is occurring the most times, or in other words is the *most common*, this would be temperature 35. If we think about it intuitively, is it the best answer? Certainly not! The average temperature by our intuition and looking at the numbers is somewhere below 30. Luckily we have another tool from descriptive statistics at our disposal - median.

**Median** is also a rather simple tool, as it simply finds the *middle observation*. The way we do that is rather straightforward; we sort the observations from smallest to largest and take the one in the middle. Let's use the R function to sort the temperatures and visually find the middle value.

```{r sort_summer_temperatures_celsius}
sort(summer_temperatures_celsius)
```

As we have 9 values, the median will be the fifth value, in this case 28 degrees. Let's verify it by using the R function which calculates the median automatically.

```{r median_summer_temperatures_celsius}
median(summer_temperatures_celsius)
```

Our visual calcululation was correct. If we think about it intuitively, does the calculated result make sense as an average summer temperature? Indeed it does, the *median* in this case did better job than *mode*. As you see, it depends on our population which of the two does a better job. Will median help us with our third question of providing *average salary* though?  

Here is our data regarding salaries in the country. They are already sorted from smallest to largest for simplicity.

```{r salaries_country}
salaries_country <- c(350, 400, 450, 470, 500, 520, 1200, 1270, 1300, 1460, 1500)
```

If we now calculate the median:

```{r median_salaries_country}
median(salaries_country)
```

The answer does not seem perfectly representative from our intuition. Yes, indeed the middle value calculated by median is 520, but it does not quite grasp the salaries which are above 1000. Luckily, we have our final tool among measures of central tendency - mean.

**Mean** is a bit more tricky to calculate. By calculating mean, we find a *point in the exact middle of our points* regardless of how our salaries look like. The calculation is straightforward:

> To calculate *mean*, sum all the points and then divide the result by their count.

That is not so bad, we could do it with a calculator or even on the back of an envelope. Firstly, let's get the sum of all observations:

```{r sum_salaries_country}
350 + 400 + 450 + 470 + 500 + 520 + 1200 + 1270 + 1300 + 1460 + 1500
```

We can count the points (salaries) just visually and know that there are 11 salaries provided. We can then do a final calculation:

```{r mean_manual_salaries_country}
9420 / 11
```

And finally we can verify this result by calling an R function which calculates the mean.

```{r mean_salaries_country}
mean(salaries_country)
```

The mean of approximately 856 seems a more reasonable result compared to a median of 520, to represent an *average salary* in this case.

As you see, neither of the three measures of central tendency is a silver bullet. Their success depends largely on a population which we are trying to describe. That is why it might be a good idea to look at all three of these and then face the provided answers with our intuition.  

The three measures - mode, median and mean; are actually not the most important piece of learning now. The fact, that we know our did our very **first application of Data Science** is! We started the chapter by saying that the aim of Data Science is to create valuable information out of the data, whereas this information has value for someone (our employer). Maybe we are working for a bread producer and our task is to find out how the producers can differentiate in the market - now we know that it should not be 500 grams bread. Maybe our employer is a sunscreen manufacturer and wants to figure out for which temperatures the sunscreen should be optimized - now we know that 28 degrees. Or maybe, our employer is the government trying to figure out which income groups should pay lower taxes - could be somewhere below 856 Euro.

## Not Knowing Entire Population

This field has been of interest for hundreds of years.

Breiman wrote a masterpiece of paper.

Nature gives us a box, which is a function by which a thing happens. Will we go to work today? It might depend on these factors. We are trying to estimate this function.

## Level 1: Being Aware - Reached
Congratulations! Without even realizing it, you have reached the first level which I call "Being Aware". You are now aware of what Data Science is, what it isn't, what it struggles with and what is the role of Embedded Data Scientist. Here are some key takeaways which you should have from this chapter:

1. Remember the five cornerstones upon which this book is built. If you plan on continuing reading it, these will be helpful to keep in mind.
2. Data Science is an art of creating valuable information out of data.
3. No training or online course can really prepare you for the real world. Hopefully this book will help you to go to the field as soon as possible and apply yourself, based on a level which you reached.
4. Data Science attempts to oftentimes describe a population. This can be done by measures of central tendency, such as mode, median or mean.


